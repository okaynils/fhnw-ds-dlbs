{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Challenge: Deep Learning for Images and Signals\n",
    "- Name: Nils Fahrni\n",
    "- Submission Date: t.b.d."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the performance of a U-Net semantic segmentation model differ between scenes of city streets and non-city streets in the BDD100K dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: \"WANDB_NOTEBOOK_NAME\"=\"dlbs\"\n"
     ]
    }
   ],
   "source": [
    "#%env WANDB_SILENT=True\n",
    "%env \"WANDB_NOTEBOOK_NAME\" \"dlbs\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import wandb\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1337\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Berkeley Deep Drive Dataset: https://arxiv.org/abs/1805.04687"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_DATA_PATH = os.path.join('data', 'bdd100k', 'images', '10k', 'train')\n",
    "BASE_LABELS_PATH = os.path.join('data', 'bdd100k', 'labels', 'sem_seg', 'masks', 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration\n",
    "\n",
    "[Become one with the data](https://karpathy.github.io/2019/04/25/recipe/#:~:text=1.%20Become%20one%20with%20the%20data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatial Heatmap\n",
    "\n",
    "https://doc.bdd100k.com/format.html#semantic-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {\n",
    "    0: \"road\",\n",
    "    1: \"sidewalk\",\n",
    "    2: \"building\",\n",
    "    3: \"wall\",\n",
    "    4: \"fence\",\n",
    "    5: \"pole\",\n",
    "    6: \"traffic light\",\n",
    "    7: \"traffic sign\",\n",
    "    8: \"vegetation\",\n",
    "    9: \"terrain\",\n",
    "    10: \"sky\",\n",
    "    11: \"person\",\n",
    "    12: \"rider\",\n",
    "    13: \"car\",\n",
    "    14: \"truck\",\n",
    "    15: \"bus\",\n",
    "    16: \"train\",\n",
    "    17: \"motorcycle\",\n",
    "    18: \"bicycle\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "label_folder = BASE_LABELS_PATH\n",
    "\n",
    "target_width, target_height = 128, 228\n",
    "N_SAMPLES = 1000\n",
    "\n",
    "heatmaps = {class_id: np.zeros((target_height, target_width), dtype=np.float32) for class_id in class_dict.keys()}\n",
    "\n",
    "for class_id, class_name in tqdm(class_dict.items(), desc=\"Processing Classes\"):\n",
    "    all_files = [f for f in os.listdir(label_folder) if f.endswith('.png')]\n",
    "    sampled_files = random.sample(all_files, min(N_SAMPLES, len(all_files)))\n",
    "    \n",
    "    for file in tqdm(sampled_files, desc=f\"Sampling {class_name}\", leave=False):\n",
    "        label_path = os.path.join(label_folder, file)\n",
    "        with Image.open(label_path) as img:\n",
    "            label = np.array(img)\n",
    "            \n",
    "            label_resized = np.array(Image.fromarray(label).resize((target_width, target_height), Image.NEAREST))\n",
    "\n",
    "            mask = (label_resized == class_id)\n",
    "            heatmaps[class_id] += mask.astype(np.float32)\n",
    "\n",
    "    heatmaps[class_id] /= len(sampled_files)\n",
    "\n",
    "fig, axs = plt.subplots(4, 5, figsize=(20, 15))\n",
    "fig.suptitle(\"Spatial Heatmaps for all Classes\", fontsize=20)\n",
    "\n",
    "for class_id, class_name in class_dict.items():\n",
    "    ax = axs[class_id // 5, class_id % 5]\n",
    "    sns.heatmap(heatmaps[class_id], ax=ax, cmap=\"viridis\", cbar=False)\n",
    "    ax.set_title(class_name)\n",
    "    ax.axis('off')\n",
    "\n",
    "for i in range(len(class_dict), 4 * 5):\n",
    "    fig.delaxes(axs[i // 5, i % 5])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- Train, Rider, Motorcycle and bicycle seem to be rather underrepresented since these objects' shapes are still clearly visible and don't have a high overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Co-Occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "label_folders = [BASE_LABELS_PATH]\n",
    "num_classes = len(class_dict)\n",
    "class_names = list(class_dict.values())\n",
    "\n",
    "co_occurrence_matrix = np.zeros((num_classes, num_classes), dtype=np.int32)\n",
    "\n",
    "for label_folder in label_folders:\n",
    "    all_files = [f for f in os.listdir(label_folder) if f.endswith('.png')]\n",
    "    \n",
    "    for file in tqdm(all_files, desc=f\"Processing Masks in {label_folder}\"):\n",
    "        label_path = os.path.join(label_folder, file)\n",
    "        with Image.open(label_path) as img:\n",
    "            label = np.array(img)\n",
    "\n",
    "            unique_classes = np.unique(label)\n",
    "\n",
    "            for i in range(len(unique_classes)):\n",
    "                for j in range(i, len(unique_classes)):\n",
    "                    class_i = unique_classes[i]\n",
    "                    class_j = unique_classes[j]\n",
    "                    if class_i < num_classes and class_j < num_classes:\n",
    "                        co_occurrence_matrix[class_i, class_j] += 1\n",
    "                        if class_i != class_j:\n",
    "                            co_occurrence_matrix[class_j, class_i] += 1\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "ax = sns.heatmap(co_occurrence_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Class Co-Occurrence Matrix for Train and Val Sets\", pad=20)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Class\")\n",
    "\n",
    "ax.xaxis.tick_top()\n",
    "ax.xaxis.set_label_position('top') \n",
    "\n",
    "plt.xticks(rotation=45, ha=\"left\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluation Skeleton\n",
    "\n",
    "[Set up the end-to-end training/evaluation skeleton + get dumb baselines](https://karpathy.github.io/2019/04/25/recipe/#:~:text=Set%20up%20the%20end%2Dto%2Dend%20training/evaluation%20skeleton%20%2B%20get%20dumb%20baselines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "\n",
    "RANDOM_SEED = 1337\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading & Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Split Sizes ---\n",
      "- Train Images: 2518\n",
      "- Val Images: 454\n",
      "- Test Images: 454\n",
      "\n",
      "--- Overlap Report ---\n",
      "✔️ No overlap detected between train and validation sets.\n",
      "✔️ No overlap detected between train and test sets.\n",
      "✔️ No overlap detected between validation and test sets.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from data import BDD100KDataset, custom_split_dataset_with_det, check_dataset_overlap\n",
    "\n",
    "DET_TRAIN_PATH = './data/bdd100k/labels/det_20/det_train.json'\n",
    "DET_VAL_PATH = './data/bdd100k/labels/det_20/det_val.json'\n",
    "\n",
    "split_data = custom_split_dataset_with_det(base_data_path=BASE_DATA_PATH, \n",
    "                                           base_labels_path=BASE_LABELS_PATH, \n",
    "                                           det_train_path=DET_TRAIN_PATH, \n",
    "                                           det_val_path=DET_VAL_PATH)\n",
    "\n",
    "check_dataset_overlap(\n",
    "    split_data['train']['image_filenames'],\n",
    "    split_data['val']['image_filenames'],\n",
    "    split_data['test']['image_filenames']\n",
    ")\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((72, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "label_transform = transforms.Compose([\n",
    "    transforms.Resize((72, 128), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    transforms.Lambda(lambda x: torch.tensor(np.array(x), dtype=torch.long)),\n",
    "])\n",
    "\n",
    "train_dataset = BDD100KDataset(\n",
    "    images_dir=split_data['train']['data_folder'],\n",
    "    labels_dir=split_data['train']['labels_folder'],\n",
    "    filenames=split_data['train']['image_filenames'],\n",
    "    transform=image_transform,\n",
    "    target_transform=label_transform,\n",
    "    scene_info=split_data['train']['scene_map']\n",
    ")\n",
    "\n",
    "val_dataset = BDD100KDataset(\n",
    "    images_dir=split_data['val']['data_folder'],\n",
    "    labels_dir=split_data['val']['labels_folder'],\n",
    "    filenames=split_data['val']['image_filenames'],\n",
    "    transform=image_transform,\n",
    "    target_transform=label_transform,\n",
    "    scene_info=split_data['val']['scene_map']\n",
    ")\n",
    "\n",
    "test_dataset = BDD100KDataset(\n",
    "    images_dir=split_data['test']['data_folder'],\n",
    "    labels_dir=split_data['test']['labels_folder'],\n",
    "    filenames=split_data['test']['image_filenames'],\n",
    "    transform=image_transform,\n",
    "    target_transform=label_transform,\n",
    "    scene_info=split_data['test']['scene_map']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing Train: 100%|██████████| 2518/2518 [00:33<00:00, 75.58it/s]\n",
      "Analyzing Validation: 100%|██████████| 454/454 [00:06<00:00, 71.56it/s]\n",
      "Analyzing Test: 100%|██████████| 454/454 [00:06<00:00, 68.57it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "def map_class_names_and_order(class_distribution, class_dict):\n",
    "    ordered_classes = sorted(class_dict.keys())  # Ensure consistent class order\n",
    "    class_names = [class_dict[class_id] for class_id in ordered_classes if class_id in class_distribution]\n",
    "    proportions = [class_distribution[class_id] for class_id in ordered_classes if class_id in class_distribution]\n",
    "    return class_names, proportions\n",
    "\n",
    "def plot_class_distribution(class_distribution, title, class_dict):\n",
    "    class_names, proportions = map_class_names_and_order(class_distribution, class_dict)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(class_names, proportions, color='skyblue', edgecolor='black')\n",
    "    \n",
    "    for bar, proportion in zip(bars, proportions):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), \n",
    "                 f\"{proportion * 100:.2f}%\", ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Proportion of Pixels')\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_class_distribution(dataset, num_classes, dataset_name):\n",
    "    class_counts = Counter()\n",
    "    \n",
    "    for idx in trange(len(dataset), desc=f\"Analyzing {dataset_name}\"):\n",
    "        try:\n",
    "            _, mask, _ = dataset[idx]  # Access dataset item\n",
    "            mask_array = np.array(mask)  # Convert mask to numpy array\n",
    "            unique, counts = np.unique(mask_array, return_counts=True)\n",
    "            class_counts.update(dict(zip(unique, counts)))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing index {idx}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Normalize counts\n",
    "    total_pixels = sum(class_counts.values())\n",
    "    class_distribution = {cls: count / total_pixels for cls, count in class_counts.items()}\n",
    "\n",
    "    return class_counts, class_distribution\n",
    "\n",
    "train_class_counts, train_class_distribution = analyze_class_distribution(train_dataset, num_classes=19, dataset_name=\"Train\")\n",
    "val_class_counts, val_class_distribution = analyze_class_distribution(val_dataset, num_classes=19, dataset_name=\"Validation\")\n",
    "test_class_counts, test_class_distribution = analyze_class_distribution(test_dataset, num_classes=19, dataset_name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "plot_class_distribution(train_class_distribution, \"Train Class Distribution\", class_dict)\n",
    "plot_class_distribution(val_class_distribution, \"Validation Class Distribution\", class_dict)\n",
    "plot_class_distribution(test_class_distribution, \"Test Class Distribution\", class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Evaluation Skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "ordered_class_dists = collections.OrderedDict(sorted(train_class_distribution.items()))\n",
    "class_weights = torch.tensor(list(ordered_class_dists.values()), device=device).float()[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: (Tiny-)U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_datalader = DataLoader(train_dataset[:8], batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mokaynils\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\fahrn\\Documents\\Classes\\dlbs\\fhnw-ds-dlbs\\wandb\\run-20241202_164748-cdgiirhu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/okaynils/dlbs/runs/cdgiirhu' target=\"_blank\">unet_baseline</a></strong> to <a href='https://wandb.ai/okaynils/dlbs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/okaynils/dlbs' target=\"_blank\">https://wandb.ai/okaynils/dlbs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/okaynils/dlbs/runs/cdgiirhu' target=\"_blank\">https://wandb.ai/okaynils/dlbs/runs/cdgiirhu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.8695, Train IoU: 0.1289 - Val Loss: 0.5969, Val IoU: 0.1489\n",
      "Model saved to models\\UNet_cdgiirhu.pth with val_loss 0.5969\n",
      "Epoch 2/50 - Train Loss: 0.5286, Train IoU: 0.1550 - Val Loss: 0.5626, Val IoU: 0.1557\n",
      "Model saved to models\\UNet_cdgiirhu.pth with val_loss 0.5626\n",
      "Epoch 3/50 - Train Loss: 0.4767, Train IoU: 0.1627 - Val Loss: 0.5169, Val IoU: 0.1637\n",
      "Model saved to models\\UNet_cdgiirhu.pth with val_loss 0.5169\n",
      "Epoch 4/50 - Train Loss: 0.4362, Train IoU: 0.1694 - Val Loss: 0.5483, Val IoU: 0.1627\n",
      "Epoch 5/50 - Train Loss: 0.4085, Train IoU: 0.1737 - Val Loss: 0.4645, Val IoU: 0.1737\n",
      "Model saved to models\\UNet_cdgiirhu.pth with val_loss 0.4645\n",
      "Epoch 6/50 - Train Loss: 0.3917, Train IoU: 0.1766 - Val Loss: 0.4501, Val IoU: 0.1771\n",
      "Model saved to models\\UNet_cdgiirhu.pth with val_loss 0.4501\n",
      "Epoch 7/50 - Train Loss: 0.3719, Train IoU: 0.1800 - Val Loss: 0.4350, Val IoU: 0.1814\n",
      "Model saved to models\\UNet_cdgiirhu.pth with val_loss 0.4350\n",
      "Epoch 8/50 - Train Loss: 0.3698, Train IoU: 0.1807 - Val Loss: 0.4538, Val IoU: 0.1784\n",
      "Epoch 9/50 - Train Loss: 0.3493, Train IoU: 0.1850 - Val Loss: 0.4835, Val IoU: 0.1730\n",
      "Epoch 10/50 - Train Loss: 0.3365, Train IoU: 0.1875 - Val Loss: 0.4270, Val IoU: 0.1827\n",
      "Model saved to models\\UNet_cdgiirhu.pth with val_loss 0.4270\n",
      "Epoch 11/50 - Train Loss: 0.3200, Train IoU: 0.1912 - Val Loss: 0.4206, Val IoU: 0.1864\n",
      "Model saved to models\\UNet_cdgiirhu.pth with val_loss 0.4206\n",
      "Epoch 12/50 - Train Loss: 0.3244, Train IoU: 0.1907 - Val Loss: 0.4092, Val IoU: 0.1839\n",
      "Model saved to models\\UNet_cdgiirhu.pth with val_loss 0.4092\n",
      "Epoch 13/50 - Train Loss: 0.3038, Train IoU: 0.1946 - Val Loss: 0.3974, Val IoU: 0.1913\n",
      "Model saved to models\\UNet_cdgiirhu.pth with val_loss 0.3974\n",
      "Epoch 14/50 - Train Loss: 0.3116, Train IoU: 0.1939 - Val Loss: 0.4067, Val IoU: 0.1888\n",
      "Epoch 15/50 - Train Loss: 0.2982, Train IoU: 0.1966 - Val Loss: 0.5220, Val IoU: 0.1751\n",
      "Epoch 16/50 - Train Loss: 0.3013, Train IoU: 0.1957 - Val Loss: 0.4125, Val IoU: 0.1910\n",
      "Epoch 17/50 - Train Loss: 0.2839, Train IoU: 0.2002 - Val Loss: 0.4215, Val IoU: 0.1871\n",
      "Epoch 18/50 - Train Loss: 0.2735, Train IoU: 0.2021 - Val Loss: 0.4171, Val IoU: 0.1905\n",
      "Epoch 19/50 - Train Loss: 0.2673, Train IoU: 0.2031 - Val Loss: 0.4029, Val IoU: 0.1924\n",
      "Epoch 20/50 - Train Loss: 0.2639, Train IoU: 0.2049 - Val Loss: 0.4200, Val IoU: 0.1895\n",
      "Epoch 21/50 - Train Loss: 0.2596, Train IoU: 0.2047 - Val Loss: 0.3875, Val IoU: 0.1964\n",
      "Model saved to models\\UNet_cdgiirhu.pth with val_loss 0.3875\n",
      "Epoch 22/50 - Train Loss: 0.2415, Train IoU: 0.2095 - Val Loss: 0.4126, Val IoU: 0.1926\n",
      "Epoch 23/50 - Train Loss: 0.2353, Train IoU: 0.2098 - Val Loss: 0.4522, Val IoU: 0.1867\n",
      "Epoch 24/50 - Train Loss: 0.2334, Train IoU: 0.2101 - Val Loss: 0.4694, Val IoU: 0.1933\n",
      "Epoch 25/50 - Train Loss: 0.2172, Train IoU: 0.2137 - Val Loss: 0.4700, Val IoU: 0.1889\n",
      "Epoch 26/50 - Train Loss: 0.2141, Train IoU: 0.2150 - Val Loss: 0.4129, Val IoU: 0.1983\n",
      "Epoch 27/50 - Train Loss: 0.2117, Train IoU: 0.2164 - Val Loss: 0.4672, Val IoU: 0.1862\n",
      "Epoch 28/50 - Train Loss: 0.2064, Train IoU: 0.2163 - Val Loss: 0.5313, Val IoU: 0.1853\n",
      "Epoch 29/50 - Train Loss: 0.2268, Train IoU: 0.2107 - Val Loss: 0.4098, Val IoU: 0.1977\n",
      "Epoch 30/50 - Train Loss: 0.1945, Train IoU: 0.2191 - Val Loss: 0.4154, Val IoU: 0.2068\n",
      "Epoch 31/50 - Train Loss: 0.1791, Train IoU: 0.2240 - Val Loss: 0.4084, Val IoU: 0.2039\n",
      "Epoch 32/50 - Train Loss: 0.1663, Train IoU: 0.2282 - Val Loss: 0.4268, Val IoU: 0.2066\n",
      "Epoch 33/50 - Train Loss: 0.1578, Train IoU: 0.2330 - Val Loss: 0.4230, Val IoU: 0.2077\n",
      "Epoch 34/50 - Train Loss: 0.1593, Train IoU: 0.2338 - Val Loss: 0.4946, Val IoU: 0.1946\n",
      "Epoch 35/50 - Train Loss: 0.1755, Train IoU: 0.2271 - Val Loss: 0.4309, Val IoU: 0.2043\n",
      "Epoch 36/50 - Train Loss: 0.1601, Train IoU: 0.2328 - Val Loss: 0.4415, Val IoU: 0.2015\n",
      "Epoch 37/50 - Train Loss: 0.1422, Train IoU: 0.2420 - Val Loss: 0.4456, Val IoU: 0.2080\n",
      "Epoch 38/50 - Train Loss: 0.1328, Train IoU: 0.2506 - Val Loss: 0.4435, Val IoU: 0.2169\n",
      "Epoch 39/50 - Train Loss: 0.1294, Train IoU: 0.2544 - Val Loss: 0.4581, Val IoU: 0.2149\n",
      "Epoch 40/50 - Train Loss: 0.1266, Train IoU: 0.2583 - Val Loss: 0.4697, Val IoU: 0.2138\n",
      "Epoch 41/50 - Train Loss: 0.1290, Train IoU: 0.2567 - Val Loss: 0.5082, Val IoU: 0.2081\n",
      "Epoch 42/50 - Train Loss: 0.2064, Train IoU: 0.2300 - Val Loss: 0.4320, Val IoU: 0.1946\n",
      "Epoch 43/50 - Train Loss: 0.1650, Train IoU: 0.2347 - Val Loss: 0.5089, Val IoU: 0.2090\n",
      "Epoch 44/50 - Train Loss: 0.1272, Train IoU: 0.2578 - Val Loss: 0.4716, Val IoU: 0.2198\n",
      "Epoch 45/50 - Train Loss: 0.1202, Train IoU: 0.2639 - Val Loss: 0.4619, Val IoU: 0.2191\n",
      "Epoch 46/50 - Train Loss: 0.1157, Train IoU: 0.2690 - Val Loss: 0.4773, Val IoU: 0.2258\n",
      "Epoch 47/50 - Train Loss: 0.1083, Train IoU: 0.2803 - Val Loss: 0.4853, Val IoU: 0.2249\n",
      "Epoch 48/50 - Train Loss: 0.1016, Train IoU: 0.2847 - Val Loss: 0.5321, Val IoU: 0.2262\n",
      "Epoch 49/50 - Train Loss: 0.1023, Train IoU: 0.2866 - Val Loss: 0.5287, Val IoU: 0.2259\n",
      "Epoch 50/50 - Train Loss: 0.0961, Train IoU: 0.2952 - Val Loss: 0.5201, Val IoU: 0.2283\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from core import UNetBaseline\n",
    "from core import UNetImproved\n",
    "from core import UNet\n",
    "\n",
    "encoder_dims = [64, 128, 256, 512]\n",
    "decoder_dims = [512, 256, 128, 64]\n",
    "\n",
    "model = UNet(num_classes=19, encoder_dims=encoder_dims, decoder_dims=decoder_dims).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=255, weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "Trainer(model, \n",
    "        criterion, \n",
    "        optimizer,\n",
    "        epochs=50, \n",
    "        weight_init=None, \n",
    "        seed=RANDOM_SEED, \n",
    "        device=device, \n",
    "        verbose=True, \n",
    "        run_name=\"unet_baseline\").run(train_dataloader, \n",
    "                                      val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfit\n",
    "\n",
    "[Overfit](https://karpathy.github.io/2019/04/25/recipe/#:~:text=3.-,Overfit,-At%20this%20stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "[Regularize](https://karpathy.github.io/2019/04/25/recipe/#:~:text=4.-,Regularize,-Ideally%2C%20we%20are)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the model\n",
    "\n",
    "[Tune](https://karpathy.github.io/2019/04/25/recipe/#:~:text=5.-,Tune,-You%20should%20now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembles & Leave it training\n",
    "\n",
    "[Squeeze out the juice](https://karpathy.github.io/2019/04/25/recipe/#:~:text=Squeeze%20out%20the%20juice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

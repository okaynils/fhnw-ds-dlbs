{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Challenge: Deep Learning for Images and Signals\n",
    "- Name: Nils Fahrni\n",
    "- Submission Date: t.b.d."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the performance of a U-Net semantic segmentation model differ between scenes of city streets and non-city streets in the BDD100K dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: \"WANDB_NOTEBOOK_NAME\"=\"dlbs\"\n"
     ]
    }
   ],
   "source": [
    "#%env WANDB_SILENT=True\n",
    "%env \"WANDB_NOTEBOOK_NAME\" \"dlbs\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import wandb\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1337\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Berkeley Deep Drive Dataset: https://arxiv.org/abs/1805.04687"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_DATA_PATH = os.path.join('data', 'bdd100k', 'images', '10k', 'train')\n",
    "BASE_LABELS_PATH = os.path.join('data', 'bdd100k', 'labels', 'sem_seg', 'masks', 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration\n",
    "\n",
    "[Become one with the data](https://karpathy.github.io/2019/04/25/recipe/#:~:text=1.%20Become%20one%20with%20the%20data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatial Heatmap\n",
    "\n",
    "https://doc.bdd100k.com/format.html#semantic-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {\n",
    "    0: \"road\",\n",
    "    1: \"sidewalk\",\n",
    "    2: \"building\",\n",
    "    3: \"wall\",\n",
    "    4: \"fence\",\n",
    "    5: \"pole\",\n",
    "    6: \"traffic light\",\n",
    "    7: \"traffic sign\",\n",
    "    8: \"vegetation\",\n",
    "    9: \"terrain\",\n",
    "    10: \"sky\",\n",
    "    11: \"person\",\n",
    "    12: \"rider\",\n",
    "    13: \"car\",\n",
    "    14: \"truck\",\n",
    "    15: \"bus\",\n",
    "    16: \"train\",\n",
    "    17: \"motorcycle\",\n",
    "    18: \"bicycle\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "label_folder = BASE_LABELS_PATH\n",
    "\n",
    "target_width, target_height = 128, 228\n",
    "N_SAMPLES = 1000\n",
    "\n",
    "heatmaps = {class_id: np.zeros((target_height, target_width), dtype=np.float32) for class_id in class_dict.keys()}\n",
    "\n",
    "for class_id, class_name in tqdm(class_dict.items(), desc=\"Processing Classes\"):\n",
    "    all_files = [f for f in os.listdir(label_folder) if f.endswith('.png')]\n",
    "    sampled_files = random.sample(all_files, min(N_SAMPLES, len(all_files)))\n",
    "    \n",
    "    for file in tqdm(sampled_files, desc=f\"Sampling {class_name}\", leave=False):\n",
    "        label_path = os.path.join(label_folder, file)\n",
    "        with Image.open(label_path) as img:\n",
    "            label = np.array(img)\n",
    "            \n",
    "            label_resized = np.array(Image.fromarray(label).resize((target_width, target_height), Image.NEAREST))\n",
    "\n",
    "            mask = (label_resized == class_id)\n",
    "            heatmaps[class_id] += mask.astype(np.float32)\n",
    "\n",
    "    heatmaps[class_id] /= len(sampled_files)\n",
    "\n",
    "fig, axs = plt.subplots(4, 5, figsize=(20, 15))\n",
    "fig.suptitle(\"Spatial Heatmaps for all Classes\", fontsize=20)\n",
    "\n",
    "for class_id, class_name in class_dict.items():\n",
    "    ax = axs[class_id // 5, class_id % 5]\n",
    "    sns.heatmap(heatmaps[class_id], ax=ax, cmap=\"viridis\", cbar=False)\n",
    "    ax.set_title(class_name)\n",
    "    ax.axis('off')\n",
    "\n",
    "for i in range(len(class_dict), 4 * 5):\n",
    "    fig.delaxes(axs[i // 5, i % 5])\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- Train, Rider, Motorcycle and bicycle seem to be rather underrepresented since these objects' shapes are still clearly visible and don't have a high overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Co-Occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "label_folders = [BASE_LABELS_PATH]\n",
    "num_classes = len(class_dict)\n",
    "class_names = list(class_dict.values())\n",
    "\n",
    "co_occurrence_matrix = np.zeros((num_classes, num_classes), dtype=np.int32)\n",
    "\n",
    "for label_folder in label_folders:\n",
    "    all_files = [f for f in os.listdir(label_folder) if f.endswith('.png')]\n",
    "    \n",
    "    for file in tqdm(all_files, desc=f\"Processing Masks in {label_folder}\"):\n",
    "        label_path = os.path.join(label_folder, file)\n",
    "        with Image.open(label_path) as img:\n",
    "            label = np.array(img)\n",
    "\n",
    "            unique_classes = np.unique(label)\n",
    "\n",
    "            for i in range(len(unique_classes)):\n",
    "                for j in range(i, len(unique_classes)):\n",
    "                    class_i = unique_classes[i]\n",
    "                    class_j = unique_classes[j]\n",
    "                    if class_i < num_classes and class_j < num_classes:\n",
    "                        co_occurrence_matrix[class_i, class_j] += 1\n",
    "                        if class_i != class_j:\n",
    "                            co_occurrence_matrix[class_j, class_i] += 1\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "ax = sns.heatmap(co_occurrence_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Class Co-Occurrence Matrix for Train and Val Sets\", pad=20)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Class\")\n",
    "\n",
    "ax.xaxis.tick_top()\n",
    "ax.xaxis.set_label_position('top') \n",
    "\n",
    "plt.xticks(rotation=45, ha=\"left\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluation Skeleton\n",
    "\n",
    "[Set up the end-to-end training/evaluation skeleton + get dumb baselines](https://karpathy.github.io/2019/04/25/recipe/#:~:text=Set%20up%20the%20end%2Dto%2Dend%20training/evaluation%20skeleton%20%2B%20get%20dumb%20baselines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "\n",
    "RANDOM_SEED = 1337\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading & Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Split Sizes ---\n",
      "- Train Images: 2518\n",
      "- Val Images: 454\n",
      "- Test Images: 454\n",
      "\n",
      "--- Overlap Report ---\n",
      "✔️ No overlap detected between train and validation sets.\n",
      "✔️ No overlap detected between train and test sets.\n",
      "✔️ No overlap detected between validation and test sets.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from data import BDD100KDataset, custom_split_dataset_with_det, check_dataset_overlap\n",
    "\n",
    "DET_TRAIN_PATH = './data/bdd100k/labels/det_20/det_train.json'\n",
    "DET_VAL_PATH = './data/bdd100k/labels/det_20/det_val.json'\n",
    "\n",
    "split_data = custom_split_dataset_with_det(base_data_path=BASE_DATA_PATH, \n",
    "                                           base_labels_path=BASE_LABELS_PATH, \n",
    "                                           det_train_path=DET_TRAIN_PATH, \n",
    "                                           det_val_path=DET_VAL_PATH)\n",
    "\n",
    "check_dataset_overlap(\n",
    "    split_data['train']['image_filenames'],\n",
    "    split_data['val']['image_filenames'],\n",
    "    split_data['test']['image_filenames']\n",
    ")\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((72, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "label_transform = transforms.Compose([\n",
    "    transforms.Resize((72, 128), interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    transforms.Lambda(lambda x: torch.tensor(np.array(x), dtype=torch.long)),\n",
    "])\n",
    "\n",
    "train_dataset = BDD100KDataset(\n",
    "    images_dir=split_data['train']['data_folder'],\n",
    "    labels_dir=split_data['train']['labels_folder'],\n",
    "    filenames=split_data['train']['image_filenames'],\n",
    "    transform=image_transform,\n",
    "    target_transform=label_transform,\n",
    "    scene_info=split_data['train']['scene_map']\n",
    ")\n",
    "\n",
    "val_dataset = BDD100KDataset(\n",
    "    images_dir=split_data['val']['data_folder'],\n",
    "    labels_dir=split_data['val']['labels_folder'],\n",
    "    filenames=split_data['val']['image_filenames'],\n",
    "    transform=image_transform,\n",
    "    target_transform=label_transform,\n",
    "    scene_info=split_data['val']['scene_map']\n",
    ")\n",
    "\n",
    "test_dataset = BDD100KDataset(\n",
    "    images_dir=split_data['test']['data_folder'],\n",
    "    labels_dir=split_data['test']['labels_folder'],\n",
    "    filenames=split_data['test']['image_filenames'],\n",
    "    transform=image_transform,\n",
    "    target_transform=label_transform,\n",
    "    scene_info=split_data['test']['scene_map']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing Train: 100%|██████████| 2518/2518 [00:31<00:00, 80.76it/s]\n",
      "Analyzing Validation: 100%|██████████| 454/454 [00:05<00:00, 87.01it/s]\n",
      "Analyzing Test: 100%|██████████| 454/454 [00:05<00:00, 85.32it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "def map_class_names_and_order(class_distribution, class_dict):\n",
    "    ordered_classes = sorted(class_dict.keys())  # Ensure consistent class order\n",
    "    class_names = [class_dict[class_id] for class_id in ordered_classes if class_id in class_distribution]\n",
    "    proportions = [class_distribution[class_id] for class_id in ordered_classes if class_id in class_distribution]\n",
    "    return class_names, proportions\n",
    "\n",
    "def plot_class_distribution(class_distribution, title, class_dict):\n",
    "    class_names, proportions = map_class_names_and_order(class_distribution, class_dict)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(class_names, proportions, color='skyblue', edgecolor='black')\n",
    "    \n",
    "    for bar, proportion in zip(bars, proportions):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), \n",
    "                 f\"{proportion * 100:.2f}%\", ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Proportion of Pixels')\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_class_distribution(dataset, num_classes, dataset_name):\n",
    "    class_counts = Counter()\n",
    "    \n",
    "    for idx in trange(len(dataset), desc=f\"Analyzing {dataset_name}\"):\n",
    "        try:\n",
    "            _, mask, _ = dataset[idx]  # Access dataset item\n",
    "            mask_array = np.array(mask)  # Convert mask to numpy array\n",
    "            unique, counts = np.unique(mask_array, return_counts=True)\n",
    "            class_counts.update(dict(zip(unique, counts)))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing index {idx}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Normalize counts\n",
    "    total_pixels = sum(class_counts.values())\n",
    "    class_distribution = {cls: count / total_pixels for cls, count in class_counts.items()}\n",
    "\n",
    "    return class_counts, class_distribution\n",
    "\n",
    "train_class_counts, train_class_distribution = analyze_class_distribution(train_dataset, num_classes=19, dataset_name=\"Train\")\n",
    "val_class_counts, val_class_distribution = analyze_class_distribution(val_dataset, num_classes=19, dataset_name=\"Validation\")\n",
    "test_class_counts, test_class_distribution = analyze_class_distribution(test_dataset, num_classes=19, dataset_name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "plot_class_distribution(train_class_distribution, \"Train Class Distribution\", class_dict)\n",
    "plot_class_distribution(val_class_distribution, \"Validation Class Distribution\", class_dict)\n",
    "plot_class_distribution(test_class_distribution, \"Test Class Distribution\", class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Evaluation Skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "ordered_class_dists = collections.OrderedDict(sorted(train_class_distribution.items()))\n",
    "class_weights = torch.tensor(list(ordered_class_dists.values()), device=device).float()[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: (Tiny-)U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_datalader = DataLoader(train_dataset[:8], batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trainer was already initialized. Skipping wandb initialization.\n",
      "Model unet_baseline already exists! Skipping training.\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from core import UNetBaseline\n",
    "\n",
    "model = UNetBaseline(num_classes=19).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=255, weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "Trainer(model,\n",
    "        criterion, \n",
    "        optimizer,\n",
    "        epochs=50,\n",
    "        seed=RANDOM_SEED, \n",
    "        device=device, \n",
    "        verbose=True, \n",
    "        run_name=\"unet_baseline\").run(train_dataloader, \n",
    "                                      val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfit\n",
    "\n",
    "[Overfit](https://karpathy.github.io/2019/04/25/recipe/#:~:text=3.-,Overfit,-At%20this%20stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Training with encoder_dims=[64, 128, 256, 512] and decoder_dims=[512, 256, 128, 64]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:et45x7fa) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unet_overfit_iteration_3</strong> at: <a href='https://wandb.ai/okaynils/dlbs/runs/et45x7fa' target=\"_blank\">https://wandb.ai/okaynils/dlbs/runs/et45x7fa</a><br/> View project at: <a href='https://wandb.ai/okaynils/dlbs' target=\"_blank\">https://wandb.ai/okaynils/dlbs</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241204_115604-et45x7fa\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:et45x7fa). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\fahrn\\Documents\\Classes\\dlbs\\fhnw-ds-dlbs\\wandb\\run-20241204_115649-0ilmubur</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/okaynils/dlbs/runs/0ilmubur' target=\"_blank\">unet_overfit_iteration_1</a></strong> to <a href='https://wandb.ai/okaynils/dlbs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/okaynils/dlbs' target=\"_blank\">https://wandb.ai/okaynils/dlbs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/okaynils/dlbs/runs/0ilmubur' target=\"_blank\">https://wandb.ai/okaynils/dlbs/runs/0ilmubur</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1024, 512, 256, 128, 64]\n",
      "Iteration 2: Training with encoder_dims=[64, 128, 256, 512, 1024] and decoder_dims=[1024, 512, 256, 128, 64]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:0ilmubur) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unet_overfit_iteration_1</strong> at: <a href='https://wandb.ai/okaynils/dlbs/runs/0ilmubur' target=\"_blank\">https://wandb.ai/okaynils/dlbs/runs/0ilmubur</a><br/> View project at: <a href='https://wandb.ai/okaynils/dlbs' target=\"_blank\">https://wandb.ai/okaynils/dlbs</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241204_115649-0ilmubur\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:0ilmubur). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\fahrn\\Documents\\Classes\\dlbs\\fhnw-ds-dlbs\\wandb\\run-20241204_115653-og0vhd5a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/okaynils/dlbs/runs/og0vhd5a' target=\"_blank\">unet_overfit_iteration_2</a></strong> to <a href='https://wandb.ai/okaynils/dlbs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/okaynils/dlbs' target=\"_blank\">https://wandb.ai/okaynils/dlbs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/okaynils/dlbs/runs/og0vhd5a' target=\"_blank\">https://wandb.ai/okaynils/dlbs/runs/og0vhd5a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2048, 1024, 512, 256, 128, 64]\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from core import UNet\n",
    "\n",
    "baseline_encoder_dims = [64, 128, 256, 512]\n",
    "baseline_decoder_dims = [512, 256, 128, 64]\n",
    "\n",
    "encoder_dims = baseline_encoder_dims[:]\n",
    "decoder_dims = baseline_decoder_dims[:]\n",
    "\n",
    "for iteration in range(2):\n",
    "    print(f\"Iteration {iteration + 1}: Training with encoder_dims={encoder_dims} and decoder_dims={decoder_dims}\")\n",
    "    \n",
    "    model = UNet(num_classes=19, encoder_dims=encoder_dims, decoder_dims=decoder_dims).to(device)\n",
    "    \n",
    "    Trainer(model,\n",
    "            criterion, \n",
    "            optimizer,\n",
    "            epochs=50,\n",
    "            seed=RANDOM_SEED, \n",
    "            device=device, \n",
    "            verbose=True, \n",
    "            run_name=f\"unet_overfit_iteration_{iteration + 1}\").run(train_dataloader, \n",
    "                                                                    val_dataloader)\n",
    "    \n",
    "    next_dim = encoder_dims[-1] * 2\n",
    "    encoder_dims.append(next_dim)\n",
    "    decoder_dims.insert(0, next_dim)\n",
    "    print(decoder_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "[Regularize](https://karpathy.github.io/2019/04/25/recipe/#:~:text=4.-,Regularize,-Ideally%2C%20we%20are)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the model\n",
    "\n",
    "[Tune](https://karpathy.github.io/2019/04/25/recipe/#:~:text=5.-,Tune,-You%20should%20now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembles & Leave it training\n",
    "\n",
    "[Squeeze out the juice](https://karpathy.github.io/2019/04/25/recipe/#:~:text=Squeeze%20out%20the%20juice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

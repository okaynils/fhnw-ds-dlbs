# @package _global_

run_name: "unet_attn"
experiment_name: "unet_attn"

model:
  _target_: core.AttentionUNet
  num_classes: 19
  input_channels: 3 
  base_filters: 64

trainer:
  run_name: "unet_attn"

optimizer:
  _target_: torch.optim.Adam
  lr: 0.0001
  weight_decay: 0.0001
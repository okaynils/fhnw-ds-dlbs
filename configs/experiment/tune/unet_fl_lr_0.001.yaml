# @package _global_

run_name: "unet_fl_lr_0.001"
experiment_name: "unet_fl_lr_0.001"

trainer:
  run_name: "unet_fl_lr_0.001"

optimizer:
  _target_: torch.optim.Adam
  lr: 0.001
  weight_decay: 0.0001

model:
  _target_: core.VanillaUNet
  num_classes: 5
  input_channels: 3 
  base_filters: 128

criterion:
  _target_: core.FocalLoss
  gamma: 2.0
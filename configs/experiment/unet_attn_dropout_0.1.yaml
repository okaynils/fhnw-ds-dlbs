# @package _global_

run_name: "unet_attn_dropout_0.1"
experiment_name: "unet_attn_dropout_0.1"

model:
  _target_: core.AttentionUNet
  num_classes: 5
  input_channels: 3 
  base_filters: 64
  dropout_prob: 0.1

trainer:
  run_name: "unet_attn_dropout_0.1"

optimizer:
  _target_: torch.optim.Adam
  lr: 0.0001
  weight_decay: 0.0001